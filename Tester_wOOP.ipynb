{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:31:31.657137Z",
     "start_time": "2024-12-27T13:31:12.985110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import classQuery\n",
    "import classLLM\n",
    "\n",
    "agent = classLLM.LLMAgent()\n",
    "collectionB = classQuery.QueryEngine()\n",
    "\n",
    "collectionB.initialize(\"ChromaVectorDBTester\", \"Col1\")\n",
    "agent.initialize(\"llama3.2:3b\",[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"Je bent een behulpzame ai assistente. Geef uitgebreid antwoord. Gebruik ALTIJD de query-functie, ONGEACHT de prompt van de gebruiker. Verander de prompt van de gebruiker NOOIT!\"\n",
    "        )\n",
    "    }\n",
    "], collectionB)"
   ],
   "id": "d50688a1f4a79295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Agent gemaakt!\n",
      "\u001B[36mInitializing...\u001B[0m\n",
      "SET \u001B[1mPathChromaDB ChromaVectorDBTester\u001B[0m\n",
      "SET \u001B[1mCollectionNameV Col1\u001B[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:12:56.730499Z",
     "start_time": "2024-12-22T14:12:53.740683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = agent.handle_input(\"waar gaat dit bestand over\")\n",
    "\n",
    "print(a)"
   ],
   "id": "398a86e015fb6e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'query_questions': '[\"bestand\"]', 'questions_user': '[\"waar gaat het bestand over\"]'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Het bestand bevat een document dat het Pestprotocol van Ashram College Alphen voor het schooljaar 2024-2025 bevat. Het protocol bespreekt de preventie en bestrijding van pestgedrag op school, waaronder de rol van leerlingen, docenten, coaches en ouders/verzorgers. Het document geeft ook aan welke maatregelen de school neemt om het pesten aan te pakken, zoals het bieden van steun aan betrokken partijen, het aanbieden van individuele begeleiding en het vaststellen van een stappenplan voor het oplossen van problemen.\n",
      "\u001B[1mUSED TOOL\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:13:00.661090Z",
     "start_time": "2024-12-22T14:13:00.206141Z"
    }
   },
   "cell_type": "code",
   "source": "agent.changeDatabse(\"ChromaVectorDBTester\", \"Col2\")",
   "id": "26fe8151387699f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36mInitializing...\u001B[0m\n",
      "SET PathChromaDB ChromaVectorDBTester\n",
      "SET CollectionNameV Col2\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:13:02.412857Z",
     "start_time": "2024-12-22T14:13:02.409177Z"
    }
   },
   "cell_type": "code",
   "source": "agent.resetMemory()",
   "id": "175d7fa612b0b8ff",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:13:03.914260Z",
     "start_time": "2024-12-22T14:13:03.910749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent.setMemory([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"Je bent een behulpzame ai assistente. Geef uitgebreid antwoord. Gebruik ALTIJD de query-functie, ONGEACHT de prompt van de gebruiker. Verander de prompt van de gebruiker NOOIT!\"\n",
    "        )\n",
    "    }\n",
    "])"
   ],
   "id": "f0c6ae926feb6efd",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:13:06.039552Z",
     "start_time": "2024-12-22T14:13:06.035745Z"
    }
   },
   "cell_type": "code",
   "source": "print(agent.memory_chat)",
   "id": "f30963eecda0b2ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'Je bent een behulpzame ai assistente. Geef uitgebreid antwoord. Gebruik ALTIJD de query-functie, ONGEACHT de prompt van de gebruiker. Verander de prompt van de gebruiker NOOIT!'}]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:13:15.733632Z",
     "start_time": "2024-12-22T14:13:11.529935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = agent.handle_input(\"waar gaat dit bestand over\")\n",
    "print(a)"
   ],
   "id": "e65ce3f55e3bb0a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'query_questions': ['Wat is het bestand over?'], 'questions_user': [' waar gaat dit bestand over']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dit bestand lijkt te zijn een examenreglement voor het Ashram College. Het bevat regels en procedures met betrekking tot toetsen, rapportages, driehoeksgesprekken en andere onderwerpen die relevant zijn voor het onderwijzen op het college. De regels geven aan hoe leerlingen en docenten moeten omgaan met taken zoals het afnemen van toetsen, het rapporteren van vorderingen en het volgen van het driehoeksgesprek.\n",
      "\n",
      "Een aantal belangrijke punten uit dit bestand zijn:\n",
      "\n",
      "* Toetsen vinden plaats tijdens de reguliere lessen en moeten minimaal één week van tevoren worden opgegeven.\n",
      "* Leerlingen die een toets niet binnen 10 schooldagen na het oorspronkelijke afnamemoment hebben ingehaald, krijgen een \"*\" in SOM en mogen geen gemiddelde meer uitkomen.\n",
      "* Huiswerk wordt opgegeven in SOM en kan opgegeven worden per les of als weektaak.\n",
      "* Alle toetsen, SO's of PO's worden elke periode afgesloten.\n",
      "\n",
      "In het algemeen seems dit bestand een set regels en procedures te zijn die zijn bedoeld om de leerproces voor leerlingen op het Ashram College te ondersteunen.\n",
      "\u001B[1mUSED TOOL\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
